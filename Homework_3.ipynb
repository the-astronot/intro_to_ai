{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZ2I2qF93XlS0X2SLRW6Xf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/the-astronot/intro_to_ai/blob/main/Homework_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Reqs"
      ],
      "metadata": {
        "id": "xO0TBa-YSLjF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iAoKY0DbIY4c"
      },
      "outputs": [],
      "source": [
        "# Mass imports\n",
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import ConfusionMatrixDisplay as CMD\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I'm gonna need this later\n",
        "def translate_y(y):\n",
        "  value = ((np.log(y) / np.log(2))+4)\n",
        "  return value\n",
        "\n",
        "def untranslate_y(y_mod):\n",
        "  value = np.float_power(2,(y_mod)-4)\n",
        "  return value\n",
        "\n",
        "def perc_error(pred,reality):\n",
        "  assert(len(pred) == len(reality))\n",
        "  total = len(reality)\n",
        "  diff = abs(reality-pred)\n",
        "  perc_off = diff/reality\n",
        "  summ = perc_off.sum()\n",
        "  return summ/float(total)"
      ],
      "metadata": {
        "id": "r6f7P-Ig05IX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic\n",
        "For this homework, while I am abandoning the galaxy classification that I have used previously, space-related problems continue to fascinate me, so I've found an asteroid dataset.\n",
        "\n",
        "# Open Asteroid Dataset\n",
        "I found the [Open Asteroid Dataset](https://www.kaggle.com/datasets/basu369victor/prediction-of-asteroid-diameter) on Kaggle. In this homework, I will attempt to determine the diameter of a given asteroid based on other features that are easier to observe."
      ],
      "metadata": {
        "id": "VhNK5WbiSTEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background\n",
        "Having no prior experience properly using Neural Networks or any of the python libraries related to them, I had to read up on a few articles/some documentation, which I have enumerated below:\n",
        "\n",
        "1. [General Intro to NN in Python from Medium](https://betterprogramming.pub/how-to-build-2-layer-neural-network-from-scratch-in-python-4dd44a13ebba)\n",
        "2. [Guide on Using TensorFlow and Keras for a Basic Neural Network](https://www.geeksforgeeks.org/implementing-neural-networks-using-tensorflow/)\n",
        "3. [Keras Documentation](https://www.tensorflow.org/api_docs/python/tf/keras)\n",
        "\n",
        "Being very new to all of this, when I did my original searching around for this homework, I tried to find a library that would automate as much of the process for me as possible. My first reference links to a guide for rolling up a NN mostly from scratch. This was useful for getting more comfortable with the overall idea of what I was trying to accomplish. It was also a nice stepping stone from the equations discussed in class to actual code.\n",
        "\n",
        "After some more searching, I came across another guide using the keras module inside of TensorFlow library to get around writing all of the code yourself. So for my implementation, I started off adhering to that guide and then made changes as required to better the outcome of the model.\n",
        "\n",
        "Some of those changes involved messing around with the different activation functions, loss functions, and optimizers outlined in the documentation found in my third reference. I found that documentation very useful for learning to use all of the different hyperparameters involved as well."
      ],
      "metadata": {
        "id": "ZZd2MheUTT4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation\n",
        "Now for the implementation..."
      ],
      "metadata": {
        "id": "scxo3q5TatWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "df = pd.read_csv('Asteroid_Updated.csv')\n",
        "# Take a peek at the data\n",
        "pd.set_option('display.max_columns', None)\n",
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "IQEg7drWay5o",
        "outputId": "8ae9d0cf-dbf9-4ae4-9e90-917982d04c9e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      name         a         e          i          om           w         q  \\\n",
              "0    Ceres  2.769165  0.076009  10.594067   80.305532   73.597694  2.558684   \n",
              "1   Pallas  2.772466  0.230337  34.836234  173.080063  310.048857  2.133865   \n",
              "2     Juno  2.669150  0.256942  12.988919  169.852760  248.138626  1.983332   \n",
              "3    Vesta  2.361418  0.088721   7.141771  103.810804  150.728541  2.151909   \n",
              "4  Astraea  2.574249  0.191095   5.366988  141.576605  358.687607  2.082324   \n",
              "5     Hebe  2.425160  0.203007  14.737901  138.640203  239.807490  1.932835   \n",
              "6     Iris  2.385334  0.231206   5.523651  259.563231  145.265106  1.833831   \n",
              "7    Flora  2.201764  0.156499   5.886955  110.889330  285.287462  1.857190   \n",
              "8    Metis  2.385637  0.123114   5.576816   68.908577    6.417369  2.091931   \n",
              "9   Hygiea  3.141539  0.112461   3.831560  283.202167  312.315206  2.788240   \n",
              "\n",
              "         ad     per_y  data_arc condition_code  n_obs_used     H neo pha  \\\n",
              "0  2.979647  4.608202    8822.0              0        1002  3.34   N   N   \n",
              "1  3.411067  4.616444   72318.0              0        8490  4.13   N   N   \n",
              "2  3.354967  4.360814   72684.0              0        7104  5.33   N   N   \n",
              "3  2.570926  3.628837   24288.0              0        9325  3.20   N   N   \n",
              "4  3.066174  4.130323   63507.0              0        2916  6.85   N   N   \n",
              "5  2.917485  3.776755   62329.0              0        6034  5.71   N   N   \n",
              "6  2.936837  3.684105   62452.0              0        5206  5.51   N   N   \n",
              "7  2.546339  3.267115   62655.0              0        2744  6.49   N   N   \n",
              "8  2.679342  3.684806   61821.0              0        2649  6.28   N   N   \n",
              "9  3.494839  5.568291   62175.0              0        3409  5.43   N   N   \n",
              "\n",
              "  diameter                 extent  albedo    rot_per       GM     BV     UB  \\\n",
              "0    939.4  964.4 x 964.2 x 891.8  0.0900   9.074170  62.6284  0.713  0.426   \n",
              "1      545            582x556x500  0.1010   7.813200  14.3000  0.635  0.284   \n",
              "2  246.596                    NaN  0.2140   7.210000      NaN  0.824  0.433   \n",
              "3    525.4  572.6 x 557.2 x 446.4  0.4228   5.342128  17.8000  0.782  0.492   \n",
              "4  106.699                    NaN  0.2740  16.806000      NaN  0.826  0.411   \n",
              "5   185.18                    NaN  0.2679   7.274500      NaN  0.822  0.399   \n",
              "6   199.83                    NaN  0.2766   7.139000      NaN  0.855  0.484   \n",
              "7  147.491                    NaN  0.2260  12.865000      NaN  0.885  0.489   \n",
              "8      190                    NaN  0.1180   5.079000      NaN  0.858  0.496   \n",
              "9   407.12                    NaN  0.0717  27.630000   7.0000  0.696  0.351   \n",
              "\n",
              "   IR spec_B spec_T     G      moid class         n          per          ma  \n",
              "0 NaN      C      G  0.12  1.594780   MBA  0.213885  1683.145708   77.372096  \n",
              "1 NaN      B      B  0.11  1.233240   MBA  0.213503  1686.155999   59.699133  \n",
              "2 NaN     Sk      S  0.32  1.034540   MBA  0.226019  1592.787285   34.925016  \n",
              "3 NaN      V      V  0.32  1.139480   MBA  0.271609  1325.432765   95.861936  \n",
              "4 NaN      S      S   NaN  1.095890   MBA  0.238632  1508.600458  282.366289  \n",
              "5 NaN      S      S  0.24  0.973965   MBA  0.260972  1379.459705   86.197923  \n",
              "6 NaN      S      S   NaN  0.846100   MBA  0.267535  1345.619196  140.419656  \n",
              "7 NaN    NaN      S  0.28  0.874176   MBA  0.301681  1193.313717  194.882895  \n",
              "8 NaN    NaN      S  0.17  1.106910   MBA  0.267484  1345.875362  276.861623  \n",
              "9 NaN      C      C   NaN  1.778390   MBA  0.177007  2033.818284  152.184851  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-632668f2-c833-4676-b2a3-a8e0eb17df87\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>a</th>\n",
              "      <th>e</th>\n",
              "      <th>i</th>\n",
              "      <th>om</th>\n",
              "      <th>w</th>\n",
              "      <th>q</th>\n",
              "      <th>ad</th>\n",
              "      <th>per_y</th>\n",
              "      <th>data_arc</th>\n",
              "      <th>condition_code</th>\n",
              "      <th>n_obs_used</th>\n",
              "      <th>H</th>\n",
              "      <th>neo</th>\n",
              "      <th>pha</th>\n",
              "      <th>diameter</th>\n",
              "      <th>extent</th>\n",
              "      <th>albedo</th>\n",
              "      <th>rot_per</th>\n",
              "      <th>GM</th>\n",
              "      <th>BV</th>\n",
              "      <th>UB</th>\n",
              "      <th>IR</th>\n",
              "      <th>spec_B</th>\n",
              "      <th>spec_T</th>\n",
              "      <th>G</th>\n",
              "      <th>moid</th>\n",
              "      <th>class</th>\n",
              "      <th>n</th>\n",
              "      <th>per</th>\n",
              "      <th>ma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ceres</td>\n",
              "      <td>2.769165</td>\n",
              "      <td>0.076009</td>\n",
              "      <td>10.594067</td>\n",
              "      <td>80.305532</td>\n",
              "      <td>73.597694</td>\n",
              "      <td>2.558684</td>\n",
              "      <td>2.979647</td>\n",
              "      <td>4.608202</td>\n",
              "      <td>8822.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1002</td>\n",
              "      <td>3.34</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>939.4</td>\n",
              "      <td>964.4 x 964.2 x 891.8</td>\n",
              "      <td>0.0900</td>\n",
              "      <td>9.074170</td>\n",
              "      <td>62.6284</td>\n",
              "      <td>0.713</td>\n",
              "      <td>0.426</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>G</td>\n",
              "      <td>0.12</td>\n",
              "      <td>1.594780</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.213885</td>\n",
              "      <td>1683.145708</td>\n",
              "      <td>77.372096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pallas</td>\n",
              "      <td>2.772466</td>\n",
              "      <td>0.230337</td>\n",
              "      <td>34.836234</td>\n",
              "      <td>173.080063</td>\n",
              "      <td>310.048857</td>\n",
              "      <td>2.133865</td>\n",
              "      <td>3.411067</td>\n",
              "      <td>4.616444</td>\n",
              "      <td>72318.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8490</td>\n",
              "      <td>4.13</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>545</td>\n",
              "      <td>582x556x500</td>\n",
              "      <td>0.1010</td>\n",
              "      <td>7.813200</td>\n",
              "      <td>14.3000</td>\n",
              "      <td>0.635</td>\n",
              "      <td>0.284</td>\n",
              "      <td>NaN</td>\n",
              "      <td>B</td>\n",
              "      <td>B</td>\n",
              "      <td>0.11</td>\n",
              "      <td>1.233240</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.213503</td>\n",
              "      <td>1686.155999</td>\n",
              "      <td>59.699133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Juno</td>\n",
              "      <td>2.669150</td>\n",
              "      <td>0.256942</td>\n",
              "      <td>12.988919</td>\n",
              "      <td>169.852760</td>\n",
              "      <td>248.138626</td>\n",
              "      <td>1.983332</td>\n",
              "      <td>3.354967</td>\n",
              "      <td>4.360814</td>\n",
              "      <td>72684.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7104</td>\n",
              "      <td>5.33</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>246.596</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2140</td>\n",
              "      <td>7.210000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.824</td>\n",
              "      <td>0.433</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sk</td>\n",
              "      <td>S</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.034540</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.226019</td>\n",
              "      <td>1592.787285</td>\n",
              "      <td>34.925016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Vesta</td>\n",
              "      <td>2.361418</td>\n",
              "      <td>0.088721</td>\n",
              "      <td>7.141771</td>\n",
              "      <td>103.810804</td>\n",
              "      <td>150.728541</td>\n",
              "      <td>2.151909</td>\n",
              "      <td>2.570926</td>\n",
              "      <td>3.628837</td>\n",
              "      <td>24288.0</td>\n",
              "      <td>0</td>\n",
              "      <td>9325</td>\n",
              "      <td>3.20</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>525.4</td>\n",
              "      <td>572.6 x 557.2 x 446.4</td>\n",
              "      <td>0.4228</td>\n",
              "      <td>5.342128</td>\n",
              "      <td>17.8000</td>\n",
              "      <td>0.782</td>\n",
              "      <td>0.492</td>\n",
              "      <td>NaN</td>\n",
              "      <td>V</td>\n",
              "      <td>V</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.139480</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.271609</td>\n",
              "      <td>1325.432765</td>\n",
              "      <td>95.861936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Astraea</td>\n",
              "      <td>2.574249</td>\n",
              "      <td>0.191095</td>\n",
              "      <td>5.366988</td>\n",
              "      <td>141.576605</td>\n",
              "      <td>358.687607</td>\n",
              "      <td>2.082324</td>\n",
              "      <td>3.066174</td>\n",
              "      <td>4.130323</td>\n",
              "      <td>63507.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2916</td>\n",
              "      <td>6.85</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>106.699</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2740</td>\n",
              "      <td>16.806000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.826</td>\n",
              "      <td>0.411</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.095890</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.238632</td>\n",
              "      <td>1508.600458</td>\n",
              "      <td>282.366289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Hebe</td>\n",
              "      <td>2.425160</td>\n",
              "      <td>0.203007</td>\n",
              "      <td>14.737901</td>\n",
              "      <td>138.640203</td>\n",
              "      <td>239.807490</td>\n",
              "      <td>1.932835</td>\n",
              "      <td>2.917485</td>\n",
              "      <td>3.776755</td>\n",
              "      <td>62329.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6034</td>\n",
              "      <td>5.71</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>185.18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2679</td>\n",
              "      <td>7.274500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.822</td>\n",
              "      <td>0.399</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>S</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.973965</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.260972</td>\n",
              "      <td>1379.459705</td>\n",
              "      <td>86.197923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Iris</td>\n",
              "      <td>2.385334</td>\n",
              "      <td>0.231206</td>\n",
              "      <td>5.523651</td>\n",
              "      <td>259.563231</td>\n",
              "      <td>145.265106</td>\n",
              "      <td>1.833831</td>\n",
              "      <td>2.936837</td>\n",
              "      <td>3.684105</td>\n",
              "      <td>62452.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5206</td>\n",
              "      <td>5.51</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>199.83</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2766</td>\n",
              "      <td>7.139000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.484</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.846100</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.267535</td>\n",
              "      <td>1345.619196</td>\n",
              "      <td>140.419656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Flora</td>\n",
              "      <td>2.201764</td>\n",
              "      <td>0.156499</td>\n",
              "      <td>5.886955</td>\n",
              "      <td>110.889330</td>\n",
              "      <td>285.287462</td>\n",
              "      <td>1.857190</td>\n",
              "      <td>2.546339</td>\n",
              "      <td>3.267115</td>\n",
              "      <td>62655.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2744</td>\n",
              "      <td>6.49</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>147.491</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2260</td>\n",
              "      <td>12.865000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.885</td>\n",
              "      <td>0.489</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.874176</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.301681</td>\n",
              "      <td>1193.313717</td>\n",
              "      <td>194.882895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Metis</td>\n",
              "      <td>2.385637</td>\n",
              "      <td>0.123114</td>\n",
              "      <td>5.576816</td>\n",
              "      <td>68.908577</td>\n",
              "      <td>6.417369</td>\n",
              "      <td>2.091931</td>\n",
              "      <td>2.679342</td>\n",
              "      <td>3.684806</td>\n",
              "      <td>61821.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2649</td>\n",
              "      <td>6.28</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>190</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.1180</td>\n",
              "      <td>5.079000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.858</td>\n",
              "      <td>0.496</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.106910</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.267484</td>\n",
              "      <td>1345.875362</td>\n",
              "      <td>276.861623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Hygiea</td>\n",
              "      <td>3.141539</td>\n",
              "      <td>0.112461</td>\n",
              "      <td>3.831560</td>\n",
              "      <td>283.202167</td>\n",
              "      <td>312.315206</td>\n",
              "      <td>2.788240</td>\n",
              "      <td>3.494839</td>\n",
              "      <td>5.568291</td>\n",
              "      <td>62175.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3409</td>\n",
              "      <td>5.43</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>407.12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0717</td>\n",
              "      <td>27.630000</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>0.696</td>\n",
              "      <td>0.351</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.778390</td>\n",
              "      <td>MBA</td>\n",
              "      <td>0.177007</td>\n",
              "      <td>2033.818284</td>\n",
              "      <td>152.184851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-632668f2-c833-4676-b2a3-a8e0eb17df87')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-632668f2-c833-4676-b2a3-a8e0eb17df87 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-632668f2-c833-4676-b2a3-a8e0eb17df87');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis\n",
        "That's a lot of features. I'll check for N/A values."
      ],
      "metadata": {
        "id": "vmfGx6t6bLPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "CjvFQFlFcVcI",
        "outputId": "aa3a7e23-c0c4-4743-cf22-7e1ad66d1704"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          name       a       e       i      om       w       q      ad  \\\n",
              "count   839714  839714  839714  839714  839714  839714  839714  839714   \n",
              "unique       2       2       1       1       1       1       1       2   \n",
              "top       True   False   False   False   False   False   False   False   \n",
              "freq    817747  839712  839714  839714  839714  839714  839714  839708   \n",
              "\n",
              "         per_y data_arc condition_code n_obs_used       H     neo     pha  \\\n",
              "count   839714   839714         839714     839714  839714  839714  839714   \n",
              "unique       2        2              2          1       2       2       2   \n",
              "top      False    False          False      False   False   False   False   \n",
              "freq    839713   824240         838847     839714  837025  839708  823272   \n",
              "\n",
              "       diameter  extent  albedo rot_per      GM      BV      UB      IR  \\\n",
              "count    839714  839714  839714  839714  839714  839714  839714  839714   \n",
              "unique        2       2       2       2       2       2       2       2   \n",
              "top        True    True    True    True    True    True    True    True   \n",
              "freq     702078  839696  703305  820918  839700  838693  838735  839713   \n",
              "\n",
              "        spec_B  spec_T       G    moid   class       n     per      ma  \n",
              "count   839714  839714  839714  839714  839714  839714  839714  839714  \n",
              "unique       2       2       2       2       1       2       2       2  \n",
              "top       True    True    True   False   False   False   False   False  \n",
              "freq    838048  838734  839595  823272  839714  839712  839708  839706  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6052c790-0dc3-4f1c-a018-a33e49e6960d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>a</th>\n",
              "      <th>e</th>\n",
              "      <th>i</th>\n",
              "      <th>om</th>\n",
              "      <th>w</th>\n",
              "      <th>q</th>\n",
              "      <th>ad</th>\n",
              "      <th>per_y</th>\n",
              "      <th>data_arc</th>\n",
              "      <th>condition_code</th>\n",
              "      <th>n_obs_used</th>\n",
              "      <th>H</th>\n",
              "      <th>neo</th>\n",
              "      <th>pha</th>\n",
              "      <th>diameter</th>\n",
              "      <th>extent</th>\n",
              "      <th>albedo</th>\n",
              "      <th>rot_per</th>\n",
              "      <th>GM</th>\n",
              "      <th>BV</th>\n",
              "      <th>UB</th>\n",
              "      <th>IR</th>\n",
              "      <th>spec_B</th>\n",
              "      <th>spec_T</th>\n",
              "      <th>G</th>\n",
              "      <th>moid</th>\n",
              "      <th>class</th>\n",
              "      <th>n</th>\n",
              "      <th>per</th>\n",
              "      <th>ma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>817747</td>\n",
              "      <td>839712</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839714</td>\n",
              "      <td>839708</td>\n",
              "      <td>839713</td>\n",
              "      <td>824240</td>\n",
              "      <td>838847</td>\n",
              "      <td>839714</td>\n",
              "      <td>837025</td>\n",
              "      <td>839708</td>\n",
              "      <td>823272</td>\n",
              "      <td>702078</td>\n",
              "      <td>839696</td>\n",
              "      <td>703305</td>\n",
              "      <td>820918</td>\n",
              "      <td>839700</td>\n",
              "      <td>838693</td>\n",
              "      <td>838735</td>\n",
              "      <td>839713</td>\n",
              "      <td>838048</td>\n",
              "      <td>838734</td>\n",
              "      <td>839595</td>\n",
              "      <td>823272</td>\n",
              "      <td>839714</td>\n",
              "      <td>839712</td>\n",
              "      <td>839708</td>\n",
              "      <td>839706</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6052c790-0dc3-4f1c-a018-a33e49e6960d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6052c790-0dc3-4f1c-a018-a33e49e6960d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6052c790-0dc3-4f1c-a018-a33e49e6960d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, that's a bit disconcerting. It would appear that the diameter is not null for only about 137,000 datapoints of the ~840,000 total. I guess that makes a good argument for the utility of the predictor. I expect that the number remaining should be enough to train the model sufficiently."
      ],
      "metadata": {
        "id": "roRwehnadZR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's remove those entries with null diameters\n",
        "df = df[df.diameter.isna()!=True]\n",
        "df[\"diameter\"] = df[\"diameter\"].astype(float)\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "0gqt2N1aeDp-",
        "outputId": "a0eac9f4-71f3-4114-e734-7f3adb8b73f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   a              e              i             om  \\\n",
              "count  137636.000000  137636.000000  137636.000000  137636.000000   \n",
              "mean        2.814613       0.145485      10.349182     169.827629   \n",
              "std         1.522740       0.077573       6.835111     102.713052   \n",
              "min         0.626226       0.000489       0.021855       0.000738   \n",
              "25%         2.536714       0.089623       5.120506      82.334880   \n",
              "50%         2.750859       0.138543       9.389963     160.438430   \n",
              "75%         3.092537       0.191141      13.738588     256.268387   \n",
              "max       389.145964       0.984348     170.323647     359.990858   \n",
              "\n",
              "                   w              q             ad          per_y  \\\n",
              "count  137636.000000  137636.000000  137636.000000  137636.000000   \n",
              "mean      181.904551       2.402609       3.226618       4.884248   \n",
              "std       103.556464       0.516169       2.896374      25.532565   \n",
              "min         0.004466       0.081882       0.999956       0.495569   \n",
              "25%        91.947943       2.068948       2.864438       4.040317   \n",
              "50%       183.669900       2.363897       3.167516       4.562581   \n",
              "75%       271.762261       2.685811       3.468608       5.438518   \n",
              "max       359.995174      40.465671     772.201080    7676.742943   \n",
              "\n",
              "            data_arc     n_obs_used              H       diameter  \\\n",
              "count  137498.000000  137636.000000  136889.000000  137636.000000   \n",
              "mean     8969.818601     675.027740      15.177041       5.483228   \n",
              "std      6165.176190     595.935104       1.407654       9.385735   \n",
              "min         1.000000       5.000000       3.200000       0.002500   \n",
              "25%      6291.000000     215.000000      14.400000       2.770000   \n",
              "50%      7572.000000     496.000000      15.300000       3.956000   \n",
              "75%      9731.000000     984.000000      16.100000       5.742000   \n",
              "max     72684.000000    9325.000000      29.900000     939.400000   \n",
              "\n",
              "              albedo       rot_per            GM           BV          UB  \\\n",
              "count  136406.000000  11188.000000  1.400000e+01  1005.000000  965.000000   \n",
              "mean        0.130066     23.566011  7.821928e+00     0.768844    0.364108   \n",
              "std         0.109994     74.829904  1.678880e+01     0.088327    0.095707   \n",
              "min         0.001000      0.029952  2.100000e-09     0.580000    0.120000   \n",
              "25%         0.053000      4.670000  1.022225e-03     0.700000    0.289000   \n",
              "50%         0.078000      7.560000  6.192500e-01     0.743000    0.360000   \n",
              "75%         0.188000     14.579500  6.500000e+00     0.850000    0.439000   \n",
              "max         1.000000   1880.000000  6.262840e+01     1.077000    0.655000   \n",
              "\n",
              "         IR           G           moid              n           per  \\\n",
              "count  1.00  119.000000  137636.000000  137636.000000  1.376360e+05   \n",
              "mean  -0.33    0.178739       1.420145       0.219640  1.783972e+03   \n",
              "std     NaN    0.134603       0.512241       0.056980  9.325769e+03   \n",
              "min   -0.33   -0.250000       0.000166       0.000128  1.810067e+02   \n",
              "25%   -0.33    0.100000       1.082523       0.181231  1.475726e+03   \n",
              "50%   -0.33    0.190000       1.384935       0.216024  1.666483e+03   \n",
              "75%   -0.33    0.250000       1.699385       0.243948  1.986419e+03   \n",
              "max   -0.33    0.600000      39.507000       1.988877  2.803930e+06   \n",
              "\n",
              "                  ma  \n",
              "count  137636.000000  \n",
              "mean      183.116785  \n",
              "std       103.411497  \n",
              "min         0.000517  \n",
              "25%        94.301261  \n",
              "50%       186.826667  \n",
              "75%       271.468299  \n",
              "max       359.999979  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb7e1b2e-29a2-4ae9-ab61-c5561f5dfb91\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>e</th>\n",
              "      <th>i</th>\n",
              "      <th>om</th>\n",
              "      <th>w</th>\n",
              "      <th>q</th>\n",
              "      <th>ad</th>\n",
              "      <th>per_y</th>\n",
              "      <th>data_arc</th>\n",
              "      <th>n_obs_used</th>\n",
              "      <th>H</th>\n",
              "      <th>diameter</th>\n",
              "      <th>albedo</th>\n",
              "      <th>rot_per</th>\n",
              "      <th>GM</th>\n",
              "      <th>BV</th>\n",
              "      <th>UB</th>\n",
              "      <th>IR</th>\n",
              "      <th>G</th>\n",
              "      <th>moid</th>\n",
              "      <th>n</th>\n",
              "      <th>per</th>\n",
              "      <th>ma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137498.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>136889.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>136406.000000</td>\n",
              "      <td>11188.000000</td>\n",
              "      <td>1.400000e+01</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>965.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>1.376360e+05</td>\n",
              "      <td>137636.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.814613</td>\n",
              "      <td>0.145485</td>\n",
              "      <td>10.349182</td>\n",
              "      <td>169.827629</td>\n",
              "      <td>181.904551</td>\n",
              "      <td>2.402609</td>\n",
              "      <td>3.226618</td>\n",
              "      <td>4.884248</td>\n",
              "      <td>8969.818601</td>\n",
              "      <td>675.027740</td>\n",
              "      <td>15.177041</td>\n",
              "      <td>5.483228</td>\n",
              "      <td>0.130066</td>\n",
              "      <td>23.566011</td>\n",
              "      <td>7.821928e+00</td>\n",
              "      <td>0.768844</td>\n",
              "      <td>0.364108</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.178739</td>\n",
              "      <td>1.420145</td>\n",
              "      <td>0.219640</td>\n",
              "      <td>1.783972e+03</td>\n",
              "      <td>183.116785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.522740</td>\n",
              "      <td>0.077573</td>\n",
              "      <td>6.835111</td>\n",
              "      <td>102.713052</td>\n",
              "      <td>103.556464</td>\n",
              "      <td>0.516169</td>\n",
              "      <td>2.896374</td>\n",
              "      <td>25.532565</td>\n",
              "      <td>6165.176190</td>\n",
              "      <td>595.935104</td>\n",
              "      <td>1.407654</td>\n",
              "      <td>9.385735</td>\n",
              "      <td>0.109994</td>\n",
              "      <td>74.829904</td>\n",
              "      <td>1.678880e+01</td>\n",
              "      <td>0.088327</td>\n",
              "      <td>0.095707</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.134603</td>\n",
              "      <td>0.512241</td>\n",
              "      <td>0.056980</td>\n",
              "      <td>9.325769e+03</td>\n",
              "      <td>103.411497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.626226</td>\n",
              "      <td>0.000489</td>\n",
              "      <td>0.021855</td>\n",
              "      <td>0.000738</td>\n",
              "      <td>0.004466</td>\n",
              "      <td>0.081882</td>\n",
              "      <td>0.999956</td>\n",
              "      <td>0.495569</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.029952</td>\n",
              "      <td>2.100000e-09</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>1.810067e+02</td>\n",
              "      <td>0.000517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.536714</td>\n",
              "      <td>0.089623</td>\n",
              "      <td>5.120506</td>\n",
              "      <td>82.334880</td>\n",
              "      <td>91.947943</td>\n",
              "      <td>2.068948</td>\n",
              "      <td>2.864438</td>\n",
              "      <td>4.040317</td>\n",
              "      <td>6291.000000</td>\n",
              "      <td>215.000000</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>2.770000</td>\n",
              "      <td>0.053000</td>\n",
              "      <td>4.670000</td>\n",
              "      <td>1.022225e-03</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.289000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.082523</td>\n",
              "      <td>0.181231</td>\n",
              "      <td>1.475726e+03</td>\n",
              "      <td>94.301261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.750859</td>\n",
              "      <td>0.138543</td>\n",
              "      <td>9.389963</td>\n",
              "      <td>160.438430</td>\n",
              "      <td>183.669900</td>\n",
              "      <td>2.363897</td>\n",
              "      <td>3.167516</td>\n",
              "      <td>4.562581</td>\n",
              "      <td>7572.000000</td>\n",
              "      <td>496.000000</td>\n",
              "      <td>15.300000</td>\n",
              "      <td>3.956000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>7.560000</td>\n",
              "      <td>6.192500e-01</td>\n",
              "      <td>0.743000</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.190000</td>\n",
              "      <td>1.384935</td>\n",
              "      <td>0.216024</td>\n",
              "      <td>1.666483e+03</td>\n",
              "      <td>186.826667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.092537</td>\n",
              "      <td>0.191141</td>\n",
              "      <td>13.738588</td>\n",
              "      <td>256.268387</td>\n",
              "      <td>271.762261</td>\n",
              "      <td>2.685811</td>\n",
              "      <td>3.468608</td>\n",
              "      <td>5.438518</td>\n",
              "      <td>9731.000000</td>\n",
              "      <td>984.000000</td>\n",
              "      <td>16.100000</td>\n",
              "      <td>5.742000</td>\n",
              "      <td>0.188000</td>\n",
              "      <td>14.579500</td>\n",
              "      <td>6.500000e+00</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.439000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.699385</td>\n",
              "      <td>0.243948</td>\n",
              "      <td>1.986419e+03</td>\n",
              "      <td>271.468299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>389.145964</td>\n",
              "      <td>0.984348</td>\n",
              "      <td>170.323647</td>\n",
              "      <td>359.990858</td>\n",
              "      <td>359.995174</td>\n",
              "      <td>40.465671</td>\n",
              "      <td>772.201080</td>\n",
              "      <td>7676.742943</td>\n",
              "      <td>72684.000000</td>\n",
              "      <td>9325.000000</td>\n",
              "      <td>29.900000</td>\n",
              "      <td>939.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1880.000000</td>\n",
              "      <td>6.262840e+01</td>\n",
              "      <td>1.077000</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>39.507000</td>\n",
              "      <td>1.988877</td>\n",
              "      <td>2.803930e+06</td>\n",
              "      <td>359.999979</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb7e1b2e-29a2-4ae9-ab61-c5561f5dfb91')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb7e1b2e-29a2-4ae9-ab61-c5561f5dfb91 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb7e1b2e-29a2-4ae9-ab61-c5561f5dfb91');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's better, but it looks like some columns aren't showing up. They're likely strings. Let me fix that."
      ],
      "metadata": {
        "id": "uiv2pbpLhYHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include=[\"O\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "yWWgJlzhhim5",
        "outputId": "f9148a6f-29ac-4df5-a277-b4ee218b2ea8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         name  condition_code     neo     pha                 extent spec_B  \\\n",
              "count   15124          137636  137636  137636                     16   1370   \n",
              "unique  15124              20       2       2                     16     31   \n",
              "top     Ceres               0       N       N  964.4 x 964.2 x 891.8      S   \n",
              "freq        1          126194  136786  137415                      1    368   \n",
              "\n",
              "       spec_T   class  \n",
              "count     965  137636  \n",
              "unique    128      11  \n",
              "top         S     MBA  \n",
              "freq      329  126390  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-094f023f-e0f2-4cd7-884a-67ac3007c2dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>condition_code</th>\n",
              "      <th>neo</th>\n",
              "      <th>pha</th>\n",
              "      <th>extent</th>\n",
              "      <th>spec_B</th>\n",
              "      <th>spec_T</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>15124</td>\n",
              "      <td>137636</td>\n",
              "      <td>137636</td>\n",
              "      <td>137636</td>\n",
              "      <td>16</td>\n",
              "      <td>1370</td>\n",
              "      <td>965</td>\n",
              "      <td>137636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>15124</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>31</td>\n",
              "      <td>128</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Ceres</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>964.4 x 964.2 x 891.8</td>\n",
              "      <td>S</td>\n",
              "      <td>S</td>\n",
              "      <td>MBA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>126194</td>\n",
              "      <td>136786</td>\n",
              "      <td>137415</td>\n",
              "      <td>1</td>\n",
              "      <td>368</td>\n",
              "      <td>329</td>\n",
              "      <td>126390</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-094f023f-e0f2-4cd7-884a-67ac3007c2dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-094f023f-e0f2-4cd7-884a-67ac3007c2dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-094f023f-e0f2-4cd7-884a-67ac3007c2dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"condition_code\"] = df[\"condition_code\"].astype(float)\n",
        "df.condition_code.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wcewWjOh2Jw",
        "outputId": "af56d3f3-41d2-4229-d824-49cf72474426"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    137636.000000\n",
              "mean          0.485207\n",
              "std           1.966078\n",
              "min           0.000000\n",
              "25%           0.000000\n",
              "50%           0.000000\n",
              "75%           0.000000\n",
              "max           9.000000\n",
              "Name: condition_code, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming Y/N to 1/0 for neo and pha\n",
        "df[\"neo_bool\"] = 0\n",
        "df.loc[df['neo'] == \"Y\", 'neo_bool'] = 1\n",
        "df[\"pha_bool\"] = 0\n",
        "df.loc[df['pha'] == \"Y\", 'pha_bool'] = 1\n",
        "df.drop('neo',axis=1,inplace=True)\n",
        "df.drop('pha',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "yiyIqFkXiN4e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropped Data\n",
        "I was prepared to convert the following features, but upon closer examination, they are all difficult to convert and also mostly N/A, so I ended up dropping them anyways.\n",
        "\n",
        "- name is useless to the model.\n",
        "- extent is composed of only 16 non N/A values, each of which are actually 3-dimensional bounds for the orbit of the asteroid.\n",
        "- spec_B/spec_t are the spectral taxonomic types of the asteroids. I have no meaningful way to convert that to meaningful data to be a coherent feature.\n",
        "- class is composed of 12 unique strings regarding the orbit class of the asteroid. I was originally going to drop it as well, but on second thought, I'd like to see what I can do to fix it. After all, at least it has values for each of the rows.\n",
        "\n",
        "## Fixing class\n",
        "First off, I have to get away from the variable \"class\". I've seen before that it makes python angry. Other than that though, I think I'll just assign integer values to the unique strings in ascending order. To the best of my understanding, having left linear models behind, the classifications I'm converting dont actually need to be linear, which is good, because after 20 minutes of googling I still can't seem to find exact definitions of the classifications."
      ],
      "metadata": {
        "id": "0x9NXcWijrmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('name',axis=1,inplace=True)\n",
        "df.drop('extent',axis=1,inplace=True)\n",
        "df.drop('spec_B',axis=1,inplace=True)\n",
        "df.drop('spec_T',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "3WklxbD4ovbs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = {}\n",
        "def assign_class(row):\n",
        "  string = row['class']\n",
        "  if string in classes:\n",
        "    return classes[string]\n",
        "  else:\n",
        "    classes[string] = len(classes)\n",
        "    return classes[string]"
      ],
      "metadata": {
        "id": "lA-iDlqioBvQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['class_int'] = df.apply(assign_class, axis=1)\n",
        "df.drop('class',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "VhGUqqUooXBe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check that everything was dropped correctly"
      ],
      "metadata": {
        "id": "hAf-K5O2qWBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "ATSkN4BUqyRj",
        "outputId": "4c6bd852-64b4-4b13-80ef-eed085906ef3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   a              e              i             om  \\\n",
              "count  137636.000000  137636.000000  137636.000000  137636.000000   \n",
              "mean        2.814613       0.145485      10.349182     169.827629   \n",
              "std         1.522740       0.077573       6.835111     102.713052   \n",
              "min         0.626226       0.000489       0.021855       0.000738   \n",
              "25%         2.536714       0.089623       5.120506      82.334880   \n",
              "50%         2.750859       0.138543       9.389963     160.438430   \n",
              "75%         3.092537       0.191141      13.738588     256.268387   \n",
              "max       389.145964       0.984348     170.323647     359.990858   \n",
              "\n",
              "                   w              q             ad          per_y  \\\n",
              "count  137636.000000  137636.000000  137636.000000  137636.000000   \n",
              "mean      181.904551       2.402609       3.226618       4.884248   \n",
              "std       103.556464       0.516169       2.896374      25.532565   \n",
              "min         0.004466       0.081882       0.999956       0.495569   \n",
              "25%        91.947943       2.068948       2.864438       4.040317   \n",
              "50%       183.669900       2.363897       3.167516       4.562581   \n",
              "75%       271.762261       2.685811       3.468608       5.438518   \n",
              "max       359.995174      40.465671     772.201080    7676.742943   \n",
              "\n",
              "            data_arc  condition_code     n_obs_used              H  \\\n",
              "count  137498.000000   137636.000000  137636.000000  136889.000000   \n",
              "mean     8969.818601        0.485207     675.027740      15.177041   \n",
              "std      6165.176190        1.966078     595.935104       1.407654   \n",
              "min         1.000000        0.000000       5.000000       3.200000   \n",
              "25%      6291.000000        0.000000     215.000000      14.400000   \n",
              "50%      7572.000000        0.000000     496.000000      15.300000   \n",
              "75%      9731.000000        0.000000     984.000000      16.100000   \n",
              "max     72684.000000        9.000000    9325.000000      29.900000   \n",
              "\n",
              "            diameter         albedo       rot_per            GM           BV  \\\n",
              "count  137636.000000  136406.000000  11188.000000  1.400000e+01  1005.000000   \n",
              "mean        5.483228       0.130066     23.566011  7.821928e+00     0.768844   \n",
              "std         9.385735       0.109994     74.829904  1.678880e+01     0.088327   \n",
              "min         0.002500       0.001000      0.029952  2.100000e-09     0.580000   \n",
              "25%         2.770000       0.053000      4.670000  1.022225e-03     0.700000   \n",
              "50%         3.956000       0.078000      7.560000  6.192500e-01     0.743000   \n",
              "75%         5.742000       0.188000     14.579500  6.500000e+00     0.850000   \n",
              "max       939.400000       1.000000   1880.000000  6.262840e+01     1.077000   \n",
              "\n",
              "               UB    IR           G           moid              n  \\\n",
              "count  965.000000  1.00  119.000000  137636.000000  137636.000000   \n",
              "mean     0.364108 -0.33    0.178739       1.420145       0.219640   \n",
              "std      0.095707   NaN    0.134603       0.512241       0.056980   \n",
              "min      0.120000 -0.33   -0.250000       0.000166       0.000128   \n",
              "25%      0.289000 -0.33    0.100000       1.082523       0.181231   \n",
              "50%      0.360000 -0.33    0.190000       1.384935       0.216024   \n",
              "75%      0.439000 -0.33    0.250000       1.699385       0.243948   \n",
              "max      0.655000 -0.33    0.600000      39.507000       1.988877   \n",
              "\n",
              "                per             ma       neo_bool       pha_bool  \\\n",
              "count  1.376360e+05  137636.000000  137636.000000  137636.000000   \n",
              "mean   1.783972e+03     183.116785       0.006176       0.001606   \n",
              "std    9.325769e+03     103.411497       0.078343       0.040039   \n",
              "min    1.810067e+02       0.000517       0.000000       0.000000   \n",
              "25%    1.475726e+03      94.301261       0.000000       0.000000   \n",
              "50%    1.666483e+03     186.826667       0.000000       0.000000   \n",
              "75%    1.986419e+03     271.468299       0.000000       0.000000   \n",
              "max    2.803930e+06     359.999979       1.000000       1.000000   \n",
              "\n",
              "           class_int  \n",
              "count  137636.000000  \n",
              "mean        0.184530  \n",
              "std         0.837106  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max        10.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd2d407e-b7db-4276-b025-17fa3bdaebaf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>e</th>\n",
              "      <th>i</th>\n",
              "      <th>om</th>\n",
              "      <th>w</th>\n",
              "      <th>q</th>\n",
              "      <th>ad</th>\n",
              "      <th>per_y</th>\n",
              "      <th>data_arc</th>\n",
              "      <th>condition_code</th>\n",
              "      <th>n_obs_used</th>\n",
              "      <th>H</th>\n",
              "      <th>diameter</th>\n",
              "      <th>albedo</th>\n",
              "      <th>rot_per</th>\n",
              "      <th>GM</th>\n",
              "      <th>BV</th>\n",
              "      <th>UB</th>\n",
              "      <th>IR</th>\n",
              "      <th>G</th>\n",
              "      <th>moid</th>\n",
              "      <th>n</th>\n",
              "      <th>per</th>\n",
              "      <th>ma</th>\n",
              "      <th>neo_bool</th>\n",
              "      <th>pha_bool</th>\n",
              "      <th>class_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137498.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>136889.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>136406.000000</td>\n",
              "      <td>11188.000000</td>\n",
              "      <td>1.400000e+01</td>\n",
              "      <td>1005.000000</td>\n",
              "      <td>965.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>1.376360e+05</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "      <td>137636.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.814613</td>\n",
              "      <td>0.145485</td>\n",
              "      <td>10.349182</td>\n",
              "      <td>169.827629</td>\n",
              "      <td>181.904551</td>\n",
              "      <td>2.402609</td>\n",
              "      <td>3.226618</td>\n",
              "      <td>4.884248</td>\n",
              "      <td>8969.818601</td>\n",
              "      <td>0.485207</td>\n",
              "      <td>675.027740</td>\n",
              "      <td>15.177041</td>\n",
              "      <td>5.483228</td>\n",
              "      <td>0.130066</td>\n",
              "      <td>23.566011</td>\n",
              "      <td>7.821928e+00</td>\n",
              "      <td>0.768844</td>\n",
              "      <td>0.364108</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.178739</td>\n",
              "      <td>1.420145</td>\n",
              "      <td>0.219640</td>\n",
              "      <td>1.783972e+03</td>\n",
              "      <td>183.116785</td>\n",
              "      <td>0.006176</td>\n",
              "      <td>0.001606</td>\n",
              "      <td>0.184530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.522740</td>\n",
              "      <td>0.077573</td>\n",
              "      <td>6.835111</td>\n",
              "      <td>102.713052</td>\n",
              "      <td>103.556464</td>\n",
              "      <td>0.516169</td>\n",
              "      <td>2.896374</td>\n",
              "      <td>25.532565</td>\n",
              "      <td>6165.176190</td>\n",
              "      <td>1.966078</td>\n",
              "      <td>595.935104</td>\n",
              "      <td>1.407654</td>\n",
              "      <td>9.385735</td>\n",
              "      <td>0.109994</td>\n",
              "      <td>74.829904</td>\n",
              "      <td>1.678880e+01</td>\n",
              "      <td>0.088327</td>\n",
              "      <td>0.095707</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.134603</td>\n",
              "      <td>0.512241</td>\n",
              "      <td>0.056980</td>\n",
              "      <td>9.325769e+03</td>\n",
              "      <td>103.411497</td>\n",
              "      <td>0.078343</td>\n",
              "      <td>0.040039</td>\n",
              "      <td>0.837106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.626226</td>\n",
              "      <td>0.000489</td>\n",
              "      <td>0.021855</td>\n",
              "      <td>0.000738</td>\n",
              "      <td>0.004466</td>\n",
              "      <td>0.081882</td>\n",
              "      <td>0.999956</td>\n",
              "      <td>0.495569</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.029952</td>\n",
              "      <td>2.100000e-09</td>\n",
              "      <td>0.580000</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>1.810067e+02</td>\n",
              "      <td>0.000517</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.536714</td>\n",
              "      <td>0.089623</td>\n",
              "      <td>5.120506</td>\n",
              "      <td>82.334880</td>\n",
              "      <td>91.947943</td>\n",
              "      <td>2.068948</td>\n",
              "      <td>2.864438</td>\n",
              "      <td>4.040317</td>\n",
              "      <td>6291.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>215.000000</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>2.770000</td>\n",
              "      <td>0.053000</td>\n",
              "      <td>4.670000</td>\n",
              "      <td>1.022225e-03</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.289000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.082523</td>\n",
              "      <td>0.181231</td>\n",
              "      <td>1.475726e+03</td>\n",
              "      <td>94.301261</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.750859</td>\n",
              "      <td>0.138543</td>\n",
              "      <td>9.389963</td>\n",
              "      <td>160.438430</td>\n",
              "      <td>183.669900</td>\n",
              "      <td>2.363897</td>\n",
              "      <td>3.167516</td>\n",
              "      <td>4.562581</td>\n",
              "      <td>7572.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>496.000000</td>\n",
              "      <td>15.300000</td>\n",
              "      <td>3.956000</td>\n",
              "      <td>0.078000</td>\n",
              "      <td>7.560000</td>\n",
              "      <td>6.192500e-01</td>\n",
              "      <td>0.743000</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.190000</td>\n",
              "      <td>1.384935</td>\n",
              "      <td>0.216024</td>\n",
              "      <td>1.666483e+03</td>\n",
              "      <td>186.826667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.092537</td>\n",
              "      <td>0.191141</td>\n",
              "      <td>13.738588</td>\n",
              "      <td>256.268387</td>\n",
              "      <td>271.762261</td>\n",
              "      <td>2.685811</td>\n",
              "      <td>3.468608</td>\n",
              "      <td>5.438518</td>\n",
              "      <td>9731.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>984.000000</td>\n",
              "      <td>16.100000</td>\n",
              "      <td>5.742000</td>\n",
              "      <td>0.188000</td>\n",
              "      <td>14.579500</td>\n",
              "      <td>6.500000e+00</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.439000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.699385</td>\n",
              "      <td>0.243948</td>\n",
              "      <td>1.986419e+03</td>\n",
              "      <td>271.468299</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>389.145964</td>\n",
              "      <td>0.984348</td>\n",
              "      <td>170.323647</td>\n",
              "      <td>359.990858</td>\n",
              "      <td>359.995174</td>\n",
              "      <td>40.465671</td>\n",
              "      <td>772.201080</td>\n",
              "      <td>7676.742943</td>\n",
              "      <td>72684.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9325.000000</td>\n",
              "      <td>29.900000</td>\n",
              "      <td>939.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1880.000000</td>\n",
              "      <td>6.262840e+01</td>\n",
              "      <td>1.077000</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>39.507000</td>\n",
              "      <td>1.988877</td>\n",
              "      <td>2.803930e+06</td>\n",
              "      <td>359.999979</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd2d407e-b7db-4276-b025-17fa3bdaebaf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd2d407e-b7db-4276-b025-17fa3bdaebaf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd2d407e-b7db-4276-b025-17fa3bdaebaf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fixing N/A Values\n",
        "Now that the string values have been taken care of, let's deal with the N/A values in the dataset."
      ],
      "metadata": {
        "id": "bbwP_sbercWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTCfTQZBqFFs",
        "outputId": "f5ba4c3d-e8f8-4917-9af5-1b99d235601f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "a                      0\n",
              "e                      0\n",
              "i                      0\n",
              "om                     0\n",
              "w                      0\n",
              "q                      0\n",
              "ad                     0\n",
              "per_y                  0\n",
              "data_arc             138\n",
              "condition_code         0\n",
              "n_obs_used             0\n",
              "H                    747\n",
              "diameter               0\n",
              "albedo              1230\n",
              "rot_per           126448\n",
              "GM                137622\n",
              "BV                136631\n",
              "UB                136671\n",
              "IR                137635\n",
              "G                 137517\n",
              "moid                   0\n",
              "n                      0\n",
              "per                    0\n",
              "ma                     0\n",
              "neo_bool               0\n",
              "pha_bool               0\n",
              "class_int              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright, so:\n",
        "\n",
        "- rot_per\n",
        "- GM\n",
        "- BV\n",
        "- UB\n",
        "- IR\n",
        "- G\n",
        "\n",
        "will have to be dropped. I can't extrapolate that much data. I should be able to do something for data_arc, H, and albedo though. All 3 of those should be alright replacing an N/A value with the average value."
      ],
      "metadata": {
        "id": "wlTFer73rtTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('rot_per',axis=1,inplace=True)\n",
        "df.drop('GM',axis=1,inplace=True)\n",
        "df.drop('BV',axis=1,inplace=True)\n",
        "df.drop('UB',axis=1,inplace=True)\n",
        "df.drop('IR',axis=1,inplace=True)\n",
        "df.drop('G',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "J7K8rjcGtrKG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['data_arc'].fillna(value=df['data_arc'].mean(), inplace=True)\n",
        "df['H'].fillna(value=df['H'].mean(), inplace=True)\n",
        "df['albedo'].fillna(value=df['albedo'].mean(), inplace=True)"
      ],
      "metadata": {
        "id": "4q40Y8Lmt6Cf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD78DniIuZhX",
        "outputId": "a92d32b8-7245-41f0-9d6f-3d8ea39f3e74"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "a                 0\n",
              "e                 0\n",
              "i                 0\n",
              "om                0\n",
              "w                 0\n",
              "q                 0\n",
              "ad                0\n",
              "per_y             0\n",
              "data_arc          0\n",
              "condition_code    0\n",
              "n_obs_used        0\n",
              "H                 0\n",
              "diameter          0\n",
              "albedo            0\n",
              "moid              0\n",
              "n                 0\n",
              "per               0\n",
              "ma                0\n",
              "neo_bool          0\n",
              "pha_bool          0\n",
              "class_int         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Relevance Check\n",
        "With the N/A values cleaned up, let's take one last check at the features to make sure that they are all meaningful and intrinsic to the asteroids. This model wouldn't be worth much if it was based off of properties that varied from observation to observation overly much.\n",
        "\n",
        "I am glad I checked. One of the features that hasn't been removed yet is the number of observations that have been made of the same asteroid. I don't see that as being a useful feature for this model. Sure, there might be a connotation attached to that data, such as the asteroids closeness to Earth, or to some extent, its size, but those should be captured by other features.\n",
        "\n",
        "Similarly, upon further reflection, the \"neo\" and \"pha\" designations were also classifications themselves made by the other features available from this repository. As such, their information should already be found within the featureset."
      ],
      "metadata": {
        "id": "6WvCJ5sLvkKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('n_obs_used',axis=1,inplace=True)\n",
        "df.drop('neo_bool',axis=1,inplace=True)\n",
        "df.drop('pha_bool',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "yrQjkAYmwBo_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation Check\n",
        "Now that the cleaning is done, let's check the correlation of the data."
      ],
      "metadata": {
        "id": "AaQEQwjHugsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "sns.heatmap(df.corr().abs(),annot=False, ax=ax, cmap='rocket_r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "T_22IumtuzjY",
        "outputId": "d0cb4bc4-bea8-4068-bf82-91105925c8ec"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9fb8af5b90>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()['diameter'].sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dpclMlsvHJC",
        "outputId": "85e60540-c307-40f7-9748-a943082e0bd4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "diameter          1.000000\n",
              "data_arc          0.491580\n",
              "moid              0.332423\n",
              "q                 0.329703\n",
              "class_int         0.157560\n",
              "a                 0.144736\n",
              "ad                0.093430\n",
              "i                 0.052609\n",
              "per               0.048953\n",
              "per_y             0.048953\n",
              "ma                0.009659\n",
              "w                 0.002966\n",
              "om                0.001164\n",
              "e                -0.049133\n",
              "condition_code   -0.073413\n",
              "albedo           -0.107334\n",
              "n                -0.201023\n",
              "H                -0.568493\n",
              "Name: diameter, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing the Correlations\n",
        "I'm still left with quite a few features here, so I think it would likely be worthwhile to drop a few features that don't seem to have much correlation with the diameter of the asteroid. From the correlation check, the features that hold little correlation with the diameter are essentially the ones that would be expected. \"w\" and \"om\" are the argument of perihelion and the longitude of the ascending node, respectively. These are too general to do much good here. \"ma\" or the mean-anomaly also makes sense here, it just doesn't really have any meaningful correlation.\n",
        "\n",
        "I also noticed that per_y and per had the same correlation, and realized that one was the period in years, while the other was the period in days. I decided I only needed one."
      ],
      "metadata": {
        "id": "o6DBzyR9xFvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('w',axis=1,inplace=True)\n",
        "df.drop('om',axis=1,inplace=True)\n",
        "df.drop('ma',axis=1,inplace=True)\n",
        "df.drop('per_y',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "r9z39FPbyy74"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "sns.heatmap(df.corr().abs(),annot=False, ax=ax, cmap='rocket_r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "O8_-m4Q6zADr",
        "outputId": "d5bfea87-f6d4-4bea-86ab-ef41a473592a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9fb5db5690>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()['diameter'].sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJXPryGPDH_w",
        "outputId": "53ca7bee-803f-4652-e195-b8fa15c09d67"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "diameter          1.000000\n",
              "data_arc          0.491580\n",
              "moid              0.332423\n",
              "q                 0.329703\n",
              "class_int         0.157560\n",
              "a                 0.144736\n",
              "ad                0.093430\n",
              "i                 0.052609\n",
              "per               0.048953\n",
              "e                -0.049133\n",
              "condition_code   -0.073413\n",
              "albedo           -0.107334\n",
              "n                -0.201023\n",
              "H                -0.568493\n",
              "Name: diameter, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partitioning the Data\n"
      ],
      "metadata": {
        "id": "7mK8ywxKzNFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# independent variables\n",
        "x = df.drop(['diameter'],axis=1)\n",
        "# dependent/target\n",
        "y = df.diameter.values\n",
        "\n",
        "# Separate Training, Validation and Test Data\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "-I7O-BhTzQNo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Scaling"
      ],
      "metadata": {
        "id": "Mr5DMrTz1lVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Normalizer(norm='max').fit(x)\n",
        "x_train = transformer.transform(x_train)\n",
        "x_test = transformer.transform(x_test)\n",
        "x_valid = transformer.transform(x_valid)"
      ],
      "metadata": {
        "id": "8aB9ThP-1nwh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras\n",
        "\n",
        "I learned to use the keras module to skip most of the work generating the minutiae of neural networks.\n",
        "\n",
        "After a lot of testing and experimentation, I settled on using Relu as the activation function, as it performed the best of all of those that I tried.\n",
        "\n",
        "I also settled on filling my 2 hidden layers with 100 nodes each, after experimenting with values between 10 and approx 250.\n",
        "\n",
        "Similarly, I decided to use adam as my optimizer, though adamax performed nearly as well. SGD was by far the worst, failing to optimize the training much at all.\n",
        "\n",
        "Finally, for the loss function, I went with MAE, or Mean Absolute Error, as it performed better overall than MSE (Mean Squared Error), the only other one that seemed to fit well."
      ],
      "metadata": {
        "id": "43SsBxuhq-Oq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Design Implementation\n",
        "\n",
        "As for the desired results of the model, I wanted to emphasize the importance of determining the order of magnitude of the size of the asteroids. With that in mind, the sizes of the asteroids included in the dataset extend from a tenth of a meter to nearly a kilometer. To this end, I decided that the model should attempt to predict the exponent to which 2 should be raised to generate the desired diameter. To accomplish this, I have added 2 functions to the start of this file, capable of transforming the y values into their related exponents and vice versa."
      ],
      "metadata": {
        "id": "ouIpg4c7IMD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=[x.shape[1]]\n",
        "print(input_shape)\n",
        "ast_model = tf.keras.Sequential([\n",
        " \n",
        "    tf.keras.layers.Dense(units=100, activation='relu',\n",
        "                          input_shape=input_shape),\n",
        "    tf.keras.layers.Dense(units=100, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1)\n",
        "])\n",
        "ast_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3uCRomfrAhN",
        "outputId": "15ac5653-c388-4883-cda4-07de950ea652"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13]\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               1400      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,601\n",
            "Trainable params: 11,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ast_model.compile(optimizer='adam', loss='mae') "
      ],
      "metadata": {
        "id": "mWWzCJMwrsbt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_check_train = translate_y(y_train)\n",
        "y_check_valid = translate_y(y_valid)\n",
        "losses = ast_model.fit(x_train, y_check_train, validation_data=(x_valid, y_check_valid), batch_size=256, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fUpXKUMr_Eg",
        "outputId": "07178010-2f2f-45ef-d8d4-749b90682659"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "388/388 [==============================] - 2s 4ms/step - loss: 1.1403 - val_loss: 0.6586\n",
            "Epoch 2/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.6552 - val_loss: 0.6554\n",
            "Epoch 3/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.6525 - val_loss: 0.6501\n",
            "Epoch 4/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.6481 - val_loss: 0.6463\n",
            "Epoch 5/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.6424 - val_loss: 0.6397\n",
            "Epoch 6/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.6365 - val_loss: 0.6319\n",
            "Epoch 7/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.6260 - val_loss: 0.6258\n",
            "Epoch 8/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.6137 - val_loss: 0.6062\n",
            "Epoch 9/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5963 - val_loss: 0.5896\n",
            "Epoch 10/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5720 - val_loss: 0.5556\n",
            "Epoch 11/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.5359 - val_loss: 0.5372\n",
            "Epoch 12/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4867 - val_loss: 0.4710\n",
            "Epoch 13/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4493 - val_loss: 0.4414\n",
            "Epoch 14/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4251 - val_loss: 0.4134\n",
            "Epoch 15/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4119 - val_loss: 0.4095\n",
            "Epoch 16/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.4388\n",
            "Epoch 17/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3885 - val_loss: 0.3848\n",
            "Epoch 18/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3885 - val_loss: 0.3949\n",
            "Epoch 19/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3805 - val_loss: 0.3754\n",
            "Epoch 20/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3766 - val_loss: 0.4266\n",
            "Epoch 21/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3772 - val_loss: 0.3855\n",
            "Epoch 22/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3739 - val_loss: 0.3754\n",
            "Epoch 23/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3704 - val_loss: 0.3717\n",
            "Epoch 24/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3676 - val_loss: 0.3665\n",
            "Epoch 25/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3678 - val_loss: 0.3775\n",
            "Epoch 26/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3653 - val_loss: 0.3800\n",
            "Epoch 27/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.3859\n",
            "Epoch 28/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3648 - val_loss: 0.3715\n",
            "Epoch 29/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.3644\n",
            "Epoch 30/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3594 - val_loss: 0.3594\n",
            "Epoch 31/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3609 - val_loss: 0.3531\n",
            "Epoch 32/200\n",
            "388/388 [==============================] - 2s 4ms/step - loss: 0.3604 - val_loss: 0.4012\n",
            "Epoch 33/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3609 - val_loss: 0.4044\n",
            "Epoch 34/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3557 - val_loss: 0.4145\n",
            "Epoch 35/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3561 - val_loss: 0.3580\n",
            "Epoch 36/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3535 - val_loss: 0.3535\n",
            "Epoch 37/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3541 - val_loss: 0.3804\n",
            "Epoch 38/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.3537\n",
            "Epoch 39/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3500 - val_loss: 0.3880\n",
            "Epoch 40/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3508 - val_loss: 0.3759\n",
            "Epoch 41/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3500 - val_loss: 0.3448\n",
            "Epoch 42/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3499 - val_loss: 0.3448\n",
            "Epoch 43/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3504 - val_loss: 0.3825\n",
            "Epoch 44/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3487 - val_loss: 0.3539\n",
            "Epoch 45/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3509 - val_loss: 0.3434\n",
            "Epoch 46/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3464 - val_loss: 0.3496\n",
            "Epoch 47/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3464 - val_loss: 0.3604\n",
            "Epoch 48/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3487 - val_loss: 0.3422\n",
            "Epoch 49/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3461 - val_loss: 0.3412\n",
            "Epoch 50/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3421 - val_loss: 0.3980\n",
            "Epoch 51/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3439 - val_loss: 0.3397\n",
            "Epoch 52/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3433 - val_loss: 0.3412\n",
            "Epoch 53/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3441 - val_loss: 0.3578\n",
            "Epoch 54/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3411 - val_loss: 0.3382\n",
            "Epoch 55/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3399 - val_loss: 0.3882\n",
            "Epoch 56/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3417 - val_loss: 0.3385\n",
            "Epoch 57/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3361 - val_loss: 0.3323\n",
            "Epoch 58/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3349 - val_loss: 0.3620\n",
            "Epoch 59/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3375 - val_loss: 0.3372\n",
            "Epoch 60/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3427 - val_loss: 0.3390\n",
            "Epoch 61/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3423 - val_loss: 0.3486\n",
            "Epoch 62/200\n",
            "388/388 [==============================] - 2s 5ms/step - loss: 0.3420 - val_loss: 0.3362\n",
            "Epoch 63/200\n",
            "388/388 [==============================] - 2s 5ms/step - loss: 0.3387 - val_loss: 0.3351\n",
            "Epoch 64/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3417 - val_loss: 0.4697\n",
            "Epoch 65/200\n",
            "388/388 [==============================] - 2s 5ms/step - loss: 0.3393 - val_loss: 0.3545\n",
            "Epoch 66/200\n",
            "388/388 [==============================] - 2s 5ms/step - loss: 0.3399 - val_loss: 0.3545\n",
            "Epoch 67/200\n",
            "388/388 [==============================] - 2s 4ms/step - loss: 0.3368 - val_loss: 0.3651\n",
            "Epoch 68/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3395 - val_loss: 0.3307\n",
            "Epoch 69/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3362 - val_loss: 0.3765\n",
            "Epoch 70/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3374 - val_loss: 0.3320\n",
            "Epoch 71/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3307 - val_loss: 0.3560\n",
            "Epoch 72/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3334 - val_loss: 0.3306\n",
            "Epoch 73/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3295 - val_loss: 0.3267\n",
            "Epoch 74/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3306 - val_loss: 0.3708\n",
            "Epoch 75/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3358 - val_loss: 0.3424\n",
            "Epoch 76/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3365 - val_loss: 0.4431\n",
            "Epoch 77/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3358 - val_loss: 0.3254\n",
            "Epoch 78/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3297 - val_loss: 0.3266\n",
            "Epoch 79/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3291 - val_loss: 0.3649\n",
            "Epoch 80/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3293 - val_loss: 0.3444\n",
            "Epoch 81/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3289 - val_loss: 0.4265\n",
            "Epoch 82/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3253 - val_loss: 0.3219\n",
            "Epoch 83/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3265 - val_loss: 0.3240\n",
            "Epoch 84/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3265 - val_loss: 0.3229\n",
            "Epoch 85/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3214 - val_loss: 0.3935\n",
            "Epoch 86/200\n",
            "388/388 [==============================] - 2s 4ms/step - loss: 0.3199 - val_loss: 0.3392\n",
            "Epoch 87/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3208 - val_loss: 0.3831\n",
            "Epoch 88/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3240 - val_loss: 0.3953\n",
            "Epoch 89/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3244 - val_loss: 0.3566\n",
            "Epoch 90/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3212 - val_loss: 0.3251\n",
            "Epoch 91/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3225 - val_loss: 0.3886\n",
            "Epoch 92/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3217 - val_loss: 0.3986\n",
            "Epoch 93/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3266 - val_loss: 0.3400\n",
            "Epoch 94/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3206 - val_loss: 0.3230\n",
            "Epoch 95/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3268 - val_loss: 0.3418\n",
            "Epoch 96/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3235 - val_loss: 0.3247\n",
            "Epoch 97/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3241 - val_loss: 0.3280\n",
            "Epoch 98/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3247 - val_loss: 0.3428\n",
            "Epoch 99/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3215 - val_loss: 0.3200\n",
            "Epoch 100/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3217 - val_loss: 0.3218\n",
            "Epoch 101/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3197 - val_loss: 0.3565\n",
            "Epoch 102/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3231 - val_loss: 0.3142\n",
            "Epoch 103/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3171 - val_loss: 0.3133\n",
            "Epoch 104/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3194 - val_loss: 0.3249\n",
            "Epoch 105/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3168 - val_loss: 0.3485\n",
            "Epoch 106/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3180 - val_loss: 0.3119\n",
            "Epoch 107/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3157 - val_loss: 0.3181\n",
            "Epoch 108/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3146 - val_loss: 0.3129\n",
            "Epoch 109/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3145 - val_loss: 0.3329\n",
            "Epoch 110/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3141 - val_loss: 0.3896\n",
            "Epoch 111/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3140 - val_loss: 0.3309\n",
            "Epoch 112/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3116 - val_loss: 0.3561\n",
            "Epoch 113/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3113 - val_loss: 0.3154\n",
            "Epoch 114/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3110 - val_loss: 0.3272\n",
            "Epoch 115/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3131 - val_loss: 0.3170\n",
            "Epoch 116/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3090 - val_loss: 0.3066\n",
            "Epoch 117/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3091 - val_loss: 0.3023\n",
            "Epoch 118/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3054 - val_loss: 0.3334\n",
            "Epoch 119/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3082 - val_loss: 0.3008\n",
            "Epoch 120/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3051 - val_loss: 0.3031\n",
            "Epoch 121/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3076 - val_loss: 0.3046\n",
            "Epoch 122/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3051 - val_loss: 0.3188\n",
            "Epoch 123/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3062 - val_loss: 0.2983\n",
            "Epoch 124/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3119 - val_loss: 0.3153\n",
            "Epoch 125/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3167 - val_loss: 0.3083\n",
            "Epoch 126/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3120 - val_loss: 0.3861\n",
            "Epoch 127/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3132 - val_loss: 0.3444\n",
            "Epoch 128/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3112 - val_loss: 0.3249\n",
            "Epoch 129/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3153 - val_loss: 0.3110\n",
            "Epoch 130/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3102 - val_loss: 0.3039\n",
            "Epoch 131/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3135 - val_loss: 0.3017\n",
            "Epoch 132/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3089 - val_loss: 0.3179\n",
            "Epoch 133/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3099 - val_loss: 0.3166\n",
            "Epoch 134/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3063 - val_loss: 0.3405\n",
            "Epoch 135/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3080 - val_loss: 0.2988\n",
            "Epoch 136/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3095 - val_loss: 0.3230\n",
            "Epoch 137/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3070 - val_loss: 0.3501\n",
            "Epoch 138/200\n",
            "388/388 [==============================] - 2s 4ms/step - loss: 0.3112 - val_loss: 0.3154\n",
            "Epoch 139/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3091 - val_loss: 0.3009\n",
            "Epoch 140/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3103 - val_loss: 0.3030\n",
            "Epoch 141/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3058 - val_loss: 0.3408\n",
            "Epoch 142/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3046 - val_loss: 0.3865\n",
            "Epoch 143/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3094 - val_loss: 0.3043\n",
            "Epoch 144/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3020 - val_loss: 0.3076\n",
            "Epoch 145/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3049 - val_loss: 0.3294\n",
            "Epoch 146/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3063 - val_loss: 0.3935\n",
            "Epoch 147/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3113 - val_loss: 0.2952\n",
            "Epoch 148/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3063 - val_loss: 0.2942\n",
            "Epoch 149/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3080 - val_loss: 0.3001\n",
            "Epoch 150/200\n",
            "388/388 [==============================] - 2s 4ms/step - loss: 0.3039 - val_loss: 0.3242\n",
            "Epoch 151/200\n",
            "388/388 [==============================] - 2s 5ms/step - loss: 0.3056 - val_loss: 0.2989\n",
            "Epoch 152/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3036 - val_loss: 0.3062\n",
            "Epoch 153/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3038 - val_loss: 0.3175\n",
            "Epoch 154/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3057 - val_loss: 0.3057\n",
            "Epoch 155/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3054 - val_loss: 0.3245\n",
            "Epoch 156/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3016 - val_loss: 0.3526\n",
            "Epoch 157/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3047 - val_loss: 0.2968\n",
            "Epoch 158/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3015 - val_loss: 0.3108\n",
            "Epoch 159/200\n",
            "388/388 [==============================] - 2s 4ms/step - loss: 0.3040 - val_loss: 0.2935\n",
            "Epoch 160/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3008 - val_loss: 0.2987\n",
            "Epoch 161/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3013 - val_loss: 0.2951\n",
            "Epoch 162/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3016 - val_loss: 0.3287\n",
            "Epoch 163/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3023 - val_loss: 0.3132\n",
            "Epoch 164/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3013 - val_loss: 0.2994\n",
            "Epoch 165/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3028 - val_loss: 0.3291\n",
            "Epoch 166/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3014 - val_loss: 0.2989\n",
            "Epoch 167/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.2984 - val_loss: 0.3345\n",
            "Epoch 168/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3024 - val_loss: 0.2929\n",
            "Epoch 169/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2992 - val_loss: 0.3583\n",
            "Epoch 170/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2987 - val_loss: 0.3160\n",
            "Epoch 171/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3015 - val_loss: 0.2930\n",
            "Epoch 172/200\n",
            "388/388 [==============================] - 2s 4ms/step - loss: 0.2992 - val_loss: 0.2921\n",
            "Epoch 173/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3022 - val_loss: 0.3047\n",
            "Epoch 174/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3009 - val_loss: 0.3557\n",
            "Epoch 175/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3005 - val_loss: 0.3010\n",
            "Epoch 176/200\n",
            "388/388 [==============================] - 2s 4ms/step - loss: 0.2981 - val_loss: 0.3317\n",
            "Epoch 177/200\n",
            "388/388 [==============================] - 2s 4ms/step - loss: 0.3007 - val_loss: 0.3079\n",
            "Epoch 178/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2989 - val_loss: 0.3280\n",
            "Epoch 179/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.2976 - val_loss: 0.2904\n",
            "Epoch 180/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3043 - val_loss: 0.3109\n",
            "Epoch 181/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2999 - val_loss: 0.2892\n",
            "Epoch 182/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.3001 - val_loss: 0.3779\n",
            "Epoch 183/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2989 - val_loss: 0.3185\n",
            "Epoch 184/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.2995 - val_loss: 0.2972\n",
            "Epoch 185/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2973 - val_loss: 0.3000\n",
            "Epoch 186/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.3001 - val_loss: 0.2902\n",
            "Epoch 187/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2975 - val_loss: 0.3467\n",
            "Epoch 188/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2990 - val_loss: 0.2881\n",
            "Epoch 189/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2995 - val_loss: 0.2974\n",
            "Epoch 190/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2963 - val_loss: 0.2966\n",
            "Epoch 191/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2970 - val_loss: 0.2977\n",
            "Epoch 192/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2978 - val_loss: 0.3437\n",
            "Epoch 193/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2961 - val_loss: 0.3050\n",
            "Epoch 194/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2972 - val_loss: 0.4710\n",
            "Epoch 195/200\n",
            "388/388 [==============================] - 2s 4ms/step - loss: 0.3006 - val_loss: 0.2951\n",
            "Epoch 196/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2955 - val_loss: 0.3046\n",
            "Epoch 197/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2972 - val_loss: 0.4019\n",
            "Epoch 198/200\n",
            "388/388 [==============================] - 1s 3ms/step - loss: 0.2997 - val_loss: 0.2919\n",
            "Epoch 199/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.2969 - val_loss: 0.3118\n",
            "Epoch 200/200\n",
            "388/388 [==============================] - 1s 4ms/step - loss: 0.2948 - val_loss: 0.3014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df = pd.DataFrame(losses.history)\n",
        "loss_df.loc[:,['loss','val_loss']].plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "p0LcwCnfOJyp",
        "outputId": "eed016b1-fc3a-49ba-f0a6-ab6564c16279"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9fb125afd0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For reference, the output layer of the system generates values between 0 and 14, inclusive. I could have divided it by 14 to fit it into 0 to 1, but I didn't because I got the same results and it was easier to explain."
      ],
      "metadata": {
        "id": "IK_JQ7qeQ3ZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = ast_model.predict(x_valid).flatten()\n",
        "print(\"VALIDATION SET: Average Error is {:.2f}% of the Diameter of the Asteroid\".format(perc_error(untranslate_y(pred),y_valid)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxZcn0IgtMJu",
        "outputId": "3526c5a1-6711-4cee-b93b-c653a60cc7df"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION SET: Average Error is 19.82% of the Diameter of the Asteroid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = ast_model.predict(x_test).flatten()\n",
        "print(\"TEST SET: Average Error is {:.2f}% of the Diameter of the Asteroid\".format(perc_error(untranslate_y(pred),y_test)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgeAVvB7cptJ",
        "outputId": "7f64818b-6b46-4e1a-affb-27d44f97d5bf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST SET: Average Error is 19.91% of the Diameter of the Asteroid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As can be seen, the model is capable of predicting the diameter of a given asteroid with an error of approximately 20% of that asteroid's diameter. That's not bad. Whether predicting an asteroid of diameter = 1 meter as having a diameter of 1.2 meters or predicting one of diameter 100 meters as 120 is pretty solid.\n",
        "\n",
        "That loss function continues to give diminishing returns as the number of epochs grows. I have run the model for 1000 epochs, and while the \n",
        "\n",
        "From how the loss on both the training and validation sets seem very low, it would appear that the model is generalizing well. Admittedly, the variance of the validation set seems to jump around increasingly as the model continues to train.\n",
        "\n",
        "I did not end up using any form of regularization, as I did not come across a way within the library to accomplish that task."
      ],
      "metadata": {
        "id": "Pn6cwh_oKUys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alternate Method\n",
        "For my alternate method, I am going to try and implement a Decision Tree to accomplish the same task."
      ],
      "metadata": {
        "id": "C5SkciCmId6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtr = DecisionTreeRegressor()\n",
        "dtr.fit(x_train,translate_y(y_train))\n",
        "pred_tree = dtr.predict(x_valid)\n",
        "pred_tree = untranslate_y(pred_tree)\n",
        "print(\"VALIDATION SET: Average Error is {:.2f}% of the Diameter of the Asteroid\".format(perc_error(pred_tree,y_valid)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1RV0kSKIobt",
        "outputId": "3da768f4-913a-457a-b93f-407b9b3b5028"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VALIDATION SET: Average Error is 15.41% of the Diameter of the Asteroid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_tree = dtr.predict(x_test)\n",
        "pred_tree = untranslate_y(pred_tree)\n",
        "print(\"TEST SET: Average Error is {:.2f}% of the Diameter of the Asteroid\".format(perc_error(pred_tree,y_test)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SewIrEY1cwSQ",
        "outputId": "ae4257e4-b58a-40a3-dec2-7f5c6ee7b538"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST SET: Average Error is 15.23% of the Diameter of the Asteroid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, that's an egg on my face. Admittedly, the problem started off seeming more complicated than it ended up being. I mean in the end I was only working with 14 features, and most of them were probably pretty linear. It's pretty embarassing that the decision tree is able to beat the average error of the neural network after functionally no computation time, whereas my model must have trained for 10 minutes.\n",
        "\n",
        "So, it makes sense that the tree model would do better. The problem is pretty straighforward relative to the features that were passed into it, and I had a whole lot of data to work with."
      ],
      "metadata": {
        "id": "jvW3o8dNKp_s"
      }
    }
  ]
}